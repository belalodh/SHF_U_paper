{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4425db-d4e0-4269-8abc-bb785efd7daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d032967-a149-4977-a4a2-dfb4b9adba92",
   "metadata": {},
   "source": [
    "# ERA5 data load and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c4e6d5-ec6f-46e2-9935-b34542f662eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIND SPEED U 10M\n",
    "ds_u10m_2014 = xr.open_dataset('/home/gopika/Bela/GISE/uv_10m/uv_10m_2014.nc')\n",
    "ds_u10m_2015 = xr.open_dataset('/home/gopika/Bela/GISE/uv_10m/uv_10m_2015.nc')\n",
    "ds_u10m_2016 = xr.open_dataset('/home/gopika/Bela/GISE/uv_10m/uv_10m_2016.nc')\n",
    "ds_u10m_2017 = xr.open_dataset('/home/gopika/Bela/GISE/uv_10m/uv_10m_2017.nc')\n",
    "ds_u10m_2018 = xr.open_dataset('/home/gopika/Bela/GISE/uv_10m/uv_10m_2018.nc')\n",
    "ds_u10m_2019 = xr.open_dataset('/home/gopika/Bela/GISE/uv_10m/uv_10m_2019.nc')\n",
    "ds_u10m_2020 = xr.open_dataset('/home/gopika/Bela/GISE/uv_10m/uv_10m_2020.nc')\n",
    "ds_u10m_2021 = xr.open_dataset('/home/gopika/Bela/GISE/uv_10m/uv_10m_2021.nc')\n",
    "ds_u10m_2022 = xr.open_dataset('/home/gopika/Bela/GISE/uv_10m/uv_10m_2022.nc')\n",
    "ds_u10m_2023 = xr.open_dataset('/home/gopika/Bela/GISE/uv_10m/uv_10m_2023.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b525000-98a4-425f-8311-286cc412c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_zonal_2014 = ds_u10m_2014.u10\n",
    "ds_zonal_2015 = ds_u10m_2015.u10\n",
    "ds_zonal_2016 = ds_u10m_2016.u10\n",
    "ds_zonal_2017 = ds_u10m_2017.u10\n",
    "ds_zonal_2018 = ds_u10m_2018.u10\n",
    "ds_zonal_2019 = ds_u10m_2019.u10\n",
    "ds_zonal_2020 = ds_u10m_2020.u10\n",
    "ds_zonal_2021 = ds_u10m_2021.u10\n",
    "ds_zonal_2022 = ds_u10m_2022.u10\n",
    "ds_zonal_2023 = ds_u10m_2023.u10\n",
    "\n",
    "ds_merid_2014 = ds_u10m_2014.v10\n",
    "ds_merid_2015 = ds_u10m_2015.v10\n",
    "ds_merid_2016 = ds_u10m_2016.v10\n",
    "ds_merid_2017 = ds_u10m_2017.v10\n",
    "ds_merid_2018 = ds_u10m_2018.v10\n",
    "ds_merid_2019 = ds_u10m_2019.v10\n",
    "ds_merid_2020 = ds_u10m_2020.v10\n",
    "ds_merid_2021 = ds_u10m_2021.v10\n",
    "ds_merid_2022 = ds_u10m_2022.v10\n",
    "ds_merid_2023 = ds_u10m_2023.v10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb11eec-05d8-4b9d-9ccf-951be887a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [ds_zonal_2014, ds_zonal_2015, ds_zonal_2016, ds_zonal_2017, ds_zonal_2018, ds_zonal_2019, ds_zonal_2020, ds_zonal_2021, ds_zonal_2022, ds_zonal_2023, ds_merid_2014, ds_merid_2015, ds_merid_2016, ds_merid_2017, ds_merid_2018, ds_merid_2019, ds_merid_2020, ds_merid_2021, ds_merid_2022, ds_merid_2023]\n",
    "datasets_jai_u10 = []\n",
    "datasets_jai_v10 = []\n",
    "for i in range(0,10):\n",
    "    ds_jai_point = datasets[i].sel(latitude=26.91, longitude=70.90, method = 'nearest')\n",
    "    datasets_jai_u10.append(ds_jai_point)\n",
    "for i in range(10,20):\n",
    "    ds_jai_point = datasets[i].sel(latitude=26.91, longitude=70.90, method = 'nearest')\n",
    "    datasets_jai_v10.append(ds_jai_point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b7c852-2b62-497e-b92e-76a90a48db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(datasets_jai_u10)):\n",
    "    datasets_jai_u10[i]['valid_time'] = datasets_jai_u10[i]['valid_time'] + pd.Timedelta(hours=5, minutes=30)\n",
    "for i in range(len(datasets_jai_v10)):\n",
    "    datasets_jai_v10[i]['valid_time'] = datasets_jai_v10[i]['valid_time'] + pd.Timedelta(hours=5, minutes=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6b14a7-e5fc-4cc0-a967-d0b796de52d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_jai_v10[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d7a056-f29f-4a97-a046-e9a1c2eab83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_jai_ws10=[]\n",
    "for i in range(10):\n",
    "    ws = (datasets_jai_u10[i]**2 + datasets_jai_v10[i]**2)**(1/2)\n",
    "    datasets_jai_ws10.append(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed2dab-1516-44af-a9c4-46091a78fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_jai_ws10[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68170ffc-3905-4a7d-aebc-5b63f2ccc985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_era5 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaebc54-3d1d-46eb-bbe9-6fadf61f0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(2014, 2024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a4f5c3-87ea-4160-862d-fe09ff0e7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(len(ds.values) for ds in datasets_jai_ws10)\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    vals = datasets_jai_ws10[i].values\n",
    "    padded = np.pad(vals, (0, max_len - len(vals)), constant_values=np.nan)\n",
    "    df_era5[f\"{year}_ws\"] = padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1698daba-dcad-4154-91b7-1ef1a2a1b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_era5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56103be-8597-452b-9702-c89248176fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "jumps = [1,2,3,4,5,6,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283c172-81b9-45c1-ad64-422ef62eb938",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    for jump in jumps:\n",
    "        df_era5[f'roc_ws_{year}_{jump}'] = df_era5[f'{year}_ws'].shift(-1*jump) - df_era5[f'{year}_ws']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc775b21-0972-474d-9b42-8147b77d1d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_era5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53e937c-e83c-466d-be57-733c34c77540",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = np.arange(0.5, 24, 1)\n",
    "shifted = np.roll(sequence, -5)\n",
    "df_era5[\"hours\"] = np.resize(shifted, len(df_era5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c554471d-7009-452f-84f4-66f0292e324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_era5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f7392-a124-47a9-ab05-65ba89335c46",
   "metadata": {},
   "source": [
    "# Obs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fa5e0c-0dd5-49ce-807c-b2431707de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs = pd.read_excel(\"/home/gopika/Bela/GISE/JSM_SH_WS_2017_infused.xlsx\", sheet_name=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2711d9d7-a71b-499e-84c4-266d0cd7eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_means_df_obs = df_obs.select_dtypes(include='number').groupby(df_obs.reset_index().index // 4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e62761-c539-447b-8157-fa9bfeb4a20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for jump in jumps:\n",
    "    hourly_means_df_obs[f'roc_ws_jump_{jump}'] = hourly_means_df_obs['WS'].shift(-1*jump) - hourly_means_df_obs['WS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed19e12-5287-468d-8b24-8a4cd3e49a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_means_df_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03074090-776d-4b2f-b562-5713d0aacc3e",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9faaa8-1e93-4b69-92d6-c7796b73a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = ['January','February','March','April','May','June',\n",
    "          'July','August','September','October','November','December']\n",
    "\n",
    "days_nonleap = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "days_leap = [31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73b631-a7a6-4c3c-8921-1cbe7b23b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freedman_diaconis_bins(data):\n",
    "    data = np.asarray(data)\n",
    "    q25, q75 = np.percentile(data, [25, 75])\n",
    "    iqr = q75 - q25\n",
    "    bin_width = 2 * iqr / (len(data) ** (1/3))\n",
    "    if bin_width == 0:\n",
    "        return 10  # fallback if data is uniform\n",
    "    bins = int(np.ceil((data.max() - data.min()) / bin_width))\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ab270f-6d83-4de0-89e6-a72463a47877",
   "metadata": {},
   "source": [
    "### all years ERA5 for different jumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25b4f90-2d5d-4563-bf85-c78a83083313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for jump in jumps:\n",
    "    for m in range(len(months)):\n",
    "        plt.figure(figsize=(10,6))\n",
    "        cmap = cm.rainbow\n",
    "        norm = mcolors.Normalize(vmin=min(years), vmax=max(years))\n",
    "        high_ramps_hour_lists = []\n",
    "        for year in years:\n",
    "            if year==2016 or year==2020:\n",
    "                days = days_leap\n",
    "            else:\n",
    "                days = days_nonleap\n",
    "            strow = sum(days[:m])*24\n",
    "            endrow = sum(days[:m+1])*24\n",
    "            era5_data = df_era5[f'roc_ws_{year}_{jump}'][strow:endrow].dropna()\n",
    "            n_bins = freedman_diaconis_bins(era5_data)\n",
    "            #print(n_bins)\n",
    "            \n",
    "            # Define bin edges\n",
    "            bins = np.linspace(era5_data.min(),era5_data.max(),n_bins)\n",
    "            \n",
    "            # Compute histogram counts (not densities)\n",
    "            era5_counts, bin_edges = np.histogram(era5_data, bins=bins)\n",
    "            \n",
    "            # Convert counts to probabilities (i.e., normalize to sum = 1)\n",
    "            era5_probs = era5_counts / era5_counts.sum()\n",
    "    \n",
    "            # Compute bin centers for plotting\n",
    "            bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    \n",
    "            # Plotting as line plot\n",
    "            plt.plot(bin_centers, era5_probs, label=f'{year}', color=cmap(norm(year)), linewidth=2, marker='o', alpha=0.5)\n",
    "    \n",
    "            #%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    \n",
    "            # Compute mean and std for ERA5 ramps (December)\n",
    "            era5_mean = era5_data.mean()\n",
    "            era5_std  = era5_data.std()\n",
    "    \n",
    "            # Define standard deviation flanks\n",
    "            era5_lower = era5_mean - era5_std\n",
    "            era5_upper = era5_mean + era5_std\n",
    "\n",
    "            # Apply the dynamic thresholding based on ±1σ\n",
    "            era5_slice = df_era5.iloc[strow:endrow]  # subset for that month/year\n",
    "\n",
    "            high_ramps = era5_slice['hours'][\n",
    "                (era5_slice[f'roc_ws_{year}_{jump}'] < era5_lower) |\n",
    "                (era5_slice[f'roc_ws_{year}_{jump}'] > era5_upper)\n",
    "            ].tolist()\n",
    "            \n",
    "            high_ramps_hour_lists.append(high_ramps)\n",
    "            #print(year) #%%%%%% r e g u l a r c h e c k\n",
    "        \n",
    "\n",
    "         # # # # # # # \n",
    "        strow = sum(days[:m])*24\n",
    "        endrow = sum(days[:m+1])*24\n",
    "        era5_data = df_era5[f'roc_ws_2017_{jump}'][strow:endrow].dropna()\n",
    "        n_bins = freedman_diaconis_bins(era5_data)\n",
    "        #print(n_bins)\n",
    "        \n",
    "        # Define bin edges\n",
    "        bins = np.linspace(era5_data.min(),era5_data.max(),n_bins)\n",
    "        \n",
    "        # Compute histogram counts (not densities)\n",
    "        era5_counts, bin_edges = np.histogram(era5_data, bins=bins)\n",
    "        \n",
    "        # Convert counts to probabilities (i.e., normalize to sum = 1)\n",
    "        era5_probs = era5_counts / era5_counts.sum()\n",
    "\n",
    "        # Compute bin centers for plotting\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "        # Plotting as line plot\n",
    "        plt.plot(bin_centers, era5_probs, color='black', linewidth=2, linestyle='--', marker='o', ms=8, alpha=0.6)\n",
    "        \n",
    "        # OBSERVATIONAL PLOT\n",
    "        strow = sum(days_nonleap[:m])*24\n",
    "        endrow = sum(days_nonleap[:m+1])*24\n",
    "        obs_data = hourly_means_df_obs[f'roc_ws_jump_{jump}'][strow:endrow].dropna()\n",
    "        n_bins = freedman_diaconis_bins(obs_data)\n",
    "        #print(n_bins)\n",
    "        \n",
    "        # Define bin edges\n",
    "        bins = np.linspace(obs_data.min(),obs_data.max(),n_bins)\n",
    "        \n",
    "        # Compute histogram counts (not densities)\n",
    "        obs_counts, bin_edges = np.histogram(obs_data, bins=bins)\n",
    "        \n",
    "        # Convert counts to probabilities (i.e., normalize to sum = 1)\n",
    "        obs_probs = obs_counts / obs_counts.sum()\n",
    "\n",
    "        # Compute bin centers for plotting\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "        # Plotting as line plot\n",
    "        plt.plot(bin_centers, obs_probs, label='Obs, 2017', color='black', linewidth=2, marker='d', markerfacecolor='none',ms=8,markeredgewidth=2)\n",
    "\n",
    "        # Plot settings\n",
    "        plt.xlabel(f'Wind speed ramp (m/s) over {jump}h', fontsize=15)\n",
    "        plt.ylabel('Kernel Density', fontsize=15)\n",
    "        plt.title(f'{months[m]}', fontsize=15)\n",
    "        plt.xticks(fontsize=15)\n",
    "        plt.yticks(fontsize=15)\n",
    "        plt.xlim(-10,10)\n",
    "        plt.ylim(-0.01, 0.175)\n",
    "        #plt.legend(fontsize=12)\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f\"/home/gopika/Bela/GISE/dpi_paper_plots/wind_ramps/ramps_{months[m]}_jump_{jump}_pdf.png\", dpi=600, bbox_inches = 'tight')\n",
    "\n",
    "        #%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "        # Compute mean and stddev for OBSV ramps\n",
    "        obs_mean = obs_data.mean()\n",
    "        obs_std  = obs_data.std()\n",
    "\n",
    "        # Define standard deviation flanks\n",
    "        obs_lower = obs_mean - obs_std\n",
    "        obs_upper = obs_mean + obs_std\n",
    "\n",
    "        # Apply the dynamic thresholding based on ±1σ\n",
    "        obs_slice = hourly_means_df_obs.iloc[strow:endrow]  # subset for that month/year\n",
    "\n",
    "        high_ramps = obs_slice['roundedhr'][\n",
    "            (obs_slice[f'roc_ws_jump_{jump}'] < obs_lower) |\n",
    "            (obs_slice[f'roc_ws_jump_{jump}'] > obs_upper)\n",
    "        ].tolist()\n",
    "\n",
    "        \n",
    "        plt.figure(figsize=(10,6))\n",
    "        cmap = cm.rainbow\n",
    "        norm = mcolors.Normalize(vmin=min(years), vmax=max(years))\n",
    "        for i in range(len(years)):\n",
    "            hourlist = np.array(high_ramps_hour_lists[i])\n",
    "            bins = np.arange(0, 25, 2)  # 24 bins for 24 hours\n",
    "            era5_counts, bin_edges = np.histogram(hourlist, bins=bins)\n",
    "            era5_probs = era5_counts / era5_counts.sum()\n",
    "            bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "            plt.plot(bin_centers, era5_probs, label=f'{years[i]}', color=cmap(norm(years[i])), linewidth=1, marker='o', alpha=0.5)\n",
    "\n",
    "        p=3\n",
    "        hourlist = np.array(high_ramps_hour_lists[p])\n",
    "        bins = np.arange(0, 25, 2)  # 24 bins for 24 hours\n",
    "        era5_counts, bin_edges = np.histogram(hourlist, bins=bins)\n",
    "        era5_probs = era5_counts / era5_counts.sum()\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        plt.plot(bin_centers, era5_probs, label=f'{years[p]}', color='black', linewidth=2, linestyle='--', marker='o', ms=8, alpha=0.6)\n",
    "        \n",
    "        \n",
    "        hourlist = np.array(high_ramps)\n",
    "        obs_counts, bin_edges = np.histogram(hourlist, bins=bins)\n",
    "        obs_probs = obs_counts / obs_counts.sum()\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        plt.plot(bin_centers, obs_probs, label='Obs, 2017', color='black', linewidth=2, marker='d', markerfacecolor='none',ms=10,markeredgewidth=2)\n",
    "        \n",
    "        plt.xlabel('Start time (hour of day)', fontsize=15)\n",
    "        plt.ylabel('Kernel Density', fontsize=15)\n",
    "        plt.title(f'High Wind Ramps (±1σ) over {jump}h, {months[m]}', fontsize=15)\n",
    "        plt.xticks(range(0, 25, 2), fontsize=15)  # Show 0–24 ticks\n",
    "        plt.yticks(fontsize=15)\n",
    "        plt.ylim(0,0.25)\n",
    "        #plt.legend(fontsize=12)\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f\"/home/gopika/Bela/GISE/dpi_paper_plots/wind_ramps/hours_{months[m]}_jump_{jump}_pdf.png\", dpi=600, bbox_inches = 'tight')\n",
    "        #print(months[m]) #%%%%%% r e g u l a r c h e c k\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f558ce1-2337-42f2-a4c9-06394d6bdf81",
   "metadata": {},
   "source": [
    "## common binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d572c55a-6f54-487b-9376-e79b526de9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freedman_diaconis_binwidth(data):\n",
    "    data = np.asarray(data)\n",
    "    data = data[~np.isnan(data)]\n",
    "    q25, q75 = np.nanpercentile(data, [25, 75])\n",
    "    iqr = q75 - q25\n",
    "    bin_width = 2 * iqr / (len(data) ** (1/3))\n",
    "    if bin_width == 0:\n",
    "        return 10  # fallback if data is uniform\n",
    "    #bins = int(np.ceil((data.max() - data.min()) / bin_width))\n",
    "    return bin_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a6a9dc-4d7f-451b-928d-07441c5a8b7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for jump in jumps:\n",
    "    for m in range(len(months)):\n",
    "        plt.figure(figsize=(10,6))\n",
    "        cmap = cm.rainbow\n",
    "        norm = mcolors.Normalize(vmin=min(years), vmax=max(years))\n",
    "        high_ramps_hour_lists = []\n",
    "        bin_widths = []\n",
    "        era5_data_years = []\n",
    "        for year in years:\n",
    "            if year==2016 or year==2020:\n",
    "                days = days_leap\n",
    "            else:\n",
    "                days = days_nonleap\n",
    "            strow = sum(days[:m])*24\n",
    "            endrow = sum(days[:m+1])*24\n",
    "            era5_data = df_era5[f'roc_ws_{year}_{jump}'][strow:endrow].dropna()\n",
    "            era5_data_years.append(era5_data)\n",
    "            bin_width = freedman_diaconis_binwidth(era5_data)\n",
    "            bin_widths.append(bin_width)\n",
    "        # determinig bin_width for observational data\n",
    "        strow = sum(days_nonleap[:m])*24\n",
    "        endrow = sum(days_nonleap[:m+1])*24\n",
    "        obs_data = hourly_means_df_obs[f'roc_ws_jump_{jump}'][strow:endrow].dropna()\n",
    "        bin_width = freedman_diaconis_binwidth(obs_data)\n",
    "        bin_widths.append(bin_width)\n",
    "\n",
    "        # what is the bin width for this month?\n",
    "        month_bin_width = min(bin_widths)\n",
    "        # computing month bins\n",
    "        month_data_years = era5_data_years + [obs_data]\n",
    "        pooled_min = min(np.nanmin(d) for d in month_data_years)\n",
    "        pooled_max = max(np.nanmax(d) for d in month_data_years)\n",
    "\n",
    "        n_bins = int(np.ceil((pooled_max - pooled_min) / month_bin_width))\n",
    "\n",
    "        bins = np.linspace(pooled_min, pooled_max, n_bins)\n",
    "\n",
    "        z=0\n",
    "        # plotting\n",
    "        for era5_data in era5_data_years:\n",
    "            \n",
    "            # Compute histogram counts (not densities)\n",
    "            era5_counts, bin_edges = np.histogram(era5_data, bins=bins)\n",
    "            \n",
    "            # Convert counts to probabilities (i.e., normalize to sum = 1)\n",
    "            era5_probs = era5_counts / era5_counts.sum()\n",
    "    \n",
    "            # Compute bin centers for plotting\n",
    "            bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    \n",
    "            # Plotting as line plot\n",
    "            plt.plot(bin_centers, era5_probs, label=f'{years[z]}', color=cmap(norm(years[z])), linewidth=2, marker='o', alpha=0.5)\n",
    "    \n",
    "            #%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    \n",
    "            # Compute mean and std for ERA5 ramps (December)\n",
    "            era5_mean = era5_data.mean()\n",
    "            era5_std  = era5_data.std()\n",
    "    \n",
    "            # Define standard deviation flanks\n",
    "            era5_lower = era5_mean - era5_std\n",
    "            era5_upper = era5_mean + era5_std\n",
    "\n",
    "            # Apply the dynamic thresholding based on ±1σ\n",
    "            era5_slice = df_era5.iloc[strow:endrow]  # subset for that month/year\n",
    "\n",
    "            high_ramps = era5_slice['hours'][\n",
    "                (era5_slice[f'roc_ws_{year}_{jump}'] < era5_lower) |\n",
    "                (era5_slice[f'roc_ws_{year}_{jump}'] > era5_upper)\n",
    "            ].tolist()\n",
    "            \n",
    "            high_ramps_hour_lists.append(high_ramps)\n",
    "            #print(year) #%%%%%% r e g u l a r c h e c k\n",
    "            z=z+1\n",
    "\n",
    "        # # # # # # # \n",
    "\n",
    "        era5_data_2017 = era5_data_years[3]\n",
    "        \n",
    "        # Compute histogram counts (not densities)\n",
    "        era5_counts, bin_edges = np.histogram(era5_data_2017, bins=bins)\n",
    "        \n",
    "        # Convert counts to probabilities (i.e., normalize to sum = 1)\n",
    "        era5_probs = era5_counts / era5_counts.sum()\n",
    "\n",
    "        # Compute bin centers for plotting\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "        # Plotting as line plot\n",
    "        plt.plot(bin_centers, era5_probs, color='black', linewidth=2, linestyle='--', marker='o', ms=8, alpha=0.6)\n",
    "       \n",
    "        # OBSERVATIONAL PLOT\n",
    "        \n",
    "        # Compute histogram counts (not densities)\n",
    "        obs_counts, bin_edges = np.histogram(obs_data, bins=bins)\n",
    "        \n",
    "        # Convert counts to probabilities (i.e., normalize to sum = 1)\n",
    "        obs_probs = obs_counts / obs_counts.sum()\n",
    "\n",
    "        # Compute bin centers for plotting\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "        # Plotting as line plot\n",
    "        plt.plot(bin_centers, obs_probs, label='Obs, 2017', color='black', linewidth=2, marker='d', markerfacecolor='none',ms=8,markeredgewidth=2)\n",
    "\n",
    "        # Plot settings\n",
    "        plt.xlabel(f'Wind speed ramp (m/s) over {jump}h', fontsize=15)\n",
    "        plt.ylabel('Kernel Density', fontsize=15)\n",
    "        plt.title(f'{months[m]}', fontsize=15)\n",
    "        plt.xticks(fontsize=15)\n",
    "        plt.yticks(fontsize=15)\n",
    "        plt.xlim(-10,10)\n",
    "        plt.ylim(-0.01, 0.175)\n",
    "        #plt.legend(fontsize=12)\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f\"/home/gopika/Bela/GISE/dpi_paper_plots/wind_ramps/common_bins/ramps_{months[m]}_jump_{jump}_pdf.png\", dpi=600, bbox_inches = 'tight')\n",
    "\n",
    "        #%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "        # Compute mean and stddev for OBSV ramps\n",
    "        obs_mean = obs_data.mean()\n",
    "        obs_std  = obs_data.std()\n",
    "\n",
    "        # Define standard deviation flanks\n",
    "        obs_lower = obs_mean - obs_std\n",
    "        obs_upper = obs_mean + obs_std\n",
    "\n",
    "        # Apply the dynamic thresholding based on ±1σ\n",
    "        obs_slice = hourly_means_df_obs.iloc[strow:endrow]  # subset for that month/year\n",
    "\n",
    "        high_ramps = obs_slice['roundedhr'][\n",
    "            (obs_slice[f'roc_ws_jump_{jump}'] < obs_lower) |\n",
    "            (obs_slice[f'roc_ws_jump_{jump}'] > obs_upper)\n",
    "        ].tolist()\n",
    "\n",
    "        \n",
    "        plt.figure(figsize=(10,6))\n",
    "        cmap = cm.rainbow\n",
    "        norm = mcolors.Normalize(vmin=min(years), vmax=max(years))\n",
    "        for i in range(len(years)):\n",
    "            hourlist = np.array(high_ramps_hour_lists[i])\n",
    "            bins = np.arange(0, 25, 2)  # 24 bins for 24 hours\n",
    "            era5_counts, bin_edges = np.histogram(hourlist, bins=bins)\n",
    "            era5_probs = era5_counts / era5_counts.sum()\n",
    "            bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "            plt.plot(bin_centers, era5_probs, label=f'{years[i]}', color=cmap(norm(years[i])), linewidth=1, marker='o', alpha=0.5)\n",
    "\n",
    "        p=3\n",
    "        hourlist = np.array(high_ramps_hour_lists[p])\n",
    "        bins = np.arange(0, 25, 2)  # 24 bins for 24 hours\n",
    "        era5_counts, bin_edges = np.histogram(hourlist, bins=bins)\n",
    "        era5_probs = era5_counts / era5_counts.sum()\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        plt.plot(bin_centers, era5_probs, label=f'{years[p]}', color='black', linewidth=2, linestyle='--', marker='o', ms=8, alpha=0.6)\n",
    "        \n",
    "        \n",
    "        hourlist = np.array(high_ramps)\n",
    "        obs_counts, bin_edges = np.histogram(hourlist, bins=bins)\n",
    "        obs_probs = obs_counts / obs_counts.sum()\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        plt.plot(bin_centers, obs_probs, label='Obs, 2017', color='black', linewidth=2, marker='d', markerfacecolor='none',ms=10,markeredgewidth=2)\n",
    "        \n",
    "        plt.xlabel('Start time (hour of day)', fontsize=15)\n",
    "        plt.ylabel('Kernel Density', fontsize=15)\n",
    "        plt.title(f'High Wind Ramps (±1σ) over {jump}h, {months[m]}', fontsize=15)\n",
    "        plt.xticks(range(0, 25, 2), fontsize=15)  # Show 0–24 ticks\n",
    "        plt.yticks(fontsize=15)\n",
    "        plt.ylim(0,0.25)\n",
    "        #plt.legend(fontsize=12)\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f\"/home/gopika/Bela/GISE/dpi_paper_plots/wind_ramps/common_bins/hours_{months[m]}_jump_{jump}_pdf.png\", dpi=600, bbox_inches = 'tight')\n",
    "        #print(months[m]) #%%%%%% r e g u l a r c h e c k\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9d4b0-8f02-4717-b2e7-86a2f5989f65",
   "metadata": {},
   "source": [
    "### combining many different ramp durations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26743e3c-df94-4cca-98f8-a25dd4d061f6",
   "metadata": {},
   "source": [
    "### trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e499c8c3-8f85-4345-8c6a-8a69a5c95231",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "data1 = np.random.rand(8,20) * 100   # frequencies (for colors)\n",
    "data2 = np.random.rand(8,20)         # probabilities (for contours)\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# Heatmap from data1\n",
    "im = plt.imshow(data1, aspect='auto', cmap='viridis', origin='lower')\n",
    "\n",
    "# Add colorbar for heatmap\n",
    "plt.colorbar(im, label=\"Frequency\")\n",
    "\n",
    "# Overlay contours from data2\n",
    "X, Y = np.meshgrid(np.arange(data2.shape[1]), np.arange(data2.shape[0]))\n",
    "contours = plt.contour(X, Y, data2, colors='white', linewidths=1.2)\n",
    "\n",
    "# Optional: add labels to contour lines\n",
    "plt.clabel(contours, inline=True, fontsize=8, fmt=\"%.2f\")\n",
    "\n",
    "# Axis labels and title\n",
    "plt.xlabel(\"Intensity bin index\")\n",
    "plt.ylabel(\"Ramp duration index\")\n",
    "plt.title(\"Heatmap (frequencies) with Contours (probabilities)\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15245379-7a08-4df2-9254-44f47b8fde9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year = 2017\n",
    "month_min_bw_era5 = []\n",
    "month_max_bw_era5 = []\n",
    "month_min_bw_obs = []\n",
    "month_max_bw_obs = []\n",
    "bins_era5_more = []\n",
    "bins_era5_less = []\n",
    "bins_obs_more = []\n",
    "bins_obs_less = []\n",
    "for m in range(len(months)):\n",
    "    era5_data_jumps = []\n",
    "    obs_data_jumps = []\n",
    "    bin_widths_era5 = []\n",
    "    bin_widths_obs = []\n",
    "    for jump in jumps:\n",
    "        strow = sum(days_nonleap[:m])*24\n",
    "        endrow = sum(days_nonleap[:m+1])*24\n",
    "        \n",
    "        era5_data = df_era5[f'roc_ws_{year}_{jump}'][strow:endrow].dropna()\n",
    "        era5_data_jumps.append(era5_data)\n",
    "        bin_width_jump = freedman_diaconis_binwidth(era5_data)\n",
    "        bin_widths_era5.append(bin_width_jump)\n",
    "\n",
    "        obs_data = hourly_means_df_obs[f'roc_ws_jump_{jump}'][strow:endrow].dropna()\n",
    "        obs_data_jumps.append(obs_data)\n",
    "        bin_width_jump = freedman_diaconis_binwidth(obs_data)\n",
    "        bin_widths_obs.append(bin_width_jump)\n",
    "        \n",
    "    print(f\"era5 {months[m]} {bin_widths_era5}\")\n",
    "    print(f\"obs {months[m]} {bin_widths_obs}\")\n",
    "    \n",
    "    month_min_bw_era5.append(min(bin_widths_era5))\n",
    "    month_max_bw_era5.append(max(bin_widths_era5))\n",
    "    nbins_era5_more = int(20/min(bin_widths_era5))\n",
    "    nbins_era5_less = int(20/max(bin_widths_era5))\n",
    "    bins_era5_more.append(np.linspace(-5, 5, nbins_era5_more))\n",
    "    bins_era5_less.append(np.linspace(-5, 5, nbins_era5_less))\n",
    "    \n",
    "    month_min_bw_obs.append(min(bin_widths_obs))\n",
    "    month_max_bw_obs.append(max(bin_widths_obs))\n",
    "    nbins_obs_more = int(20/min(bin_widths_obs))\n",
    "    nbins_obs_less = int(20/max(bin_widths_obs))\n",
    "    bins_obs_more.append(np.linspace(-5, 5, nbins_obs_more))\n",
    "    bins_obs_less.append(np.linspace(-5, 5, nbins_obs_less))\n",
    "\n",
    "print(f\"bin_era5_more {bins_era5_more}\")\n",
    "print(f\"bin_era5_less {bins_era5_less}\")\n",
    "print(f\"bin_obs_more {bins_obs_more}\")\n",
    "print(f\"bin_obs_less {bins_obs_less}\")\n",
    "\n",
    "print(len(bins_era5_more[1]))\n",
    "print(len(bins_era5_less[1]))\n",
    "print(len(bins_obs_more[1]))\n",
    "print(len(bins_obs_less[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0b09f7-08e6-4f39-b557-3f9528a4d413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year = 2017\n",
    "for m in range(len(months)):\n",
    "    month_jumps_countlist_era5 = []\n",
    "    month_jumps_problist_era5 = []\n",
    "    month_jumps_countlist_obs = []\n",
    "    month_jumps_problist_obs = []\n",
    "    for jump in jumps:\n",
    "        strow = sum(days_nonleap[:m])*24\n",
    "        endrow = sum(days_nonleap[:m+1])*24\n",
    "        \n",
    "        era5_data = df_era5[f'roc_ws_{year}_{jump}'][strow:endrow].dropna()\n",
    "        era5_counts, bin_edges = np.histogram(era5_data, bins=bins_era5_more[m]) # MORE\n",
    "        era5_probs = era5_counts / era5_counts.sum()\n",
    "        #bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        month_jumps_countlist_era5.append(era5_counts)\n",
    "        month_jumps_problist_era5.append(era5_probs)\n",
    "\n",
    "        obs_data = hourly_means_df_obs[f'roc_ws_jump_{jump}'][strow:endrow].dropna()\n",
    "        obs_counts, bin_edges = np.histogram(obs_data, bins=bins_obs_more[m])\n",
    "        obs_probs = obs_counts / obs_counts.sum()\n",
    "        #bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        month_jumps_countlist_obs.append(obs_counts)\n",
    "        month_jumps_problist_obs.append(obs_probs)\n",
    "        \n",
    "    # ERA5 heatmap\n",
    "    data1 = np.array(month_jumps_countlist_era5)\n",
    "    data2 = np.array(month_jumps_problist_era5)\n",
    "    bin_centres = (bins_era5_more[m][:-1] + bins_era5_more[m][1:]) / 2\n",
    "    # plot\n",
    "    plt.figure(figsize=(18,3))\n",
    "    im = plt.imshow(data1, aspect='auto', cmap='cubehelix_r', origin='lower',\n",
    "                extent=[min(bin_centres), max(bin_centres), 0.5, 8.5])\n",
    "    plt.colorbar(im, label=\"Frequency\", pad=0.01)\n",
    "    for y in np.arange(1.5, 8, 1):\n",
    "        plt.hlines(y, xmin=min(bin_centres), xmax=max(bin_centres), colors='gray', linestyles='-', linewidth=0.9, alpha=0.7)\n",
    "    for x in np.arange(-4, 5, 1):\n",
    "        plt.vlines(x, ymin=0.5, ymax=8.5, colors='gray', linestyles='-', linewidth=0.9, alpha=0.7)\n",
    "    X, Y = np.meshgrid(bin_centres, np.arange(1,9))\n",
    "    contours = plt.contour(X, Y, data2, colors='black', linewidths=1.2)\n",
    "    plt.clabel(contours, inline=True, fontsize=8, fmt=\"%.3f\")\n",
    "    plt.xlabel(\"Wind ramp intensity (m/s)\")\n",
    "    plt.ylabel(\"Ramp duration (hours)\")\n",
    "    plt.title(f\"{months[m]} - ERA5\")\n",
    "    plt.savefig(f\"/home/gopika/Bela/GISE/dpi_paper_plots/wind_ramps/heatmap_contours/finer_ramps_{months[m]}_era5.png\", dpi=300)\n",
    "\n",
    "    # OBSV heatmap\n",
    "    data1 = np.array(month_jumps_countlist_obs)\n",
    "    data2 = np.array(month_jumps_problist_obs)\n",
    "    bin_centres = (bins_obs_more[m][:-1] + bins_obs_more[m][1:]) / 2 # MORE\n",
    "    # plot\n",
    "    plt.figure(figsize=(18,3))\n",
    "    im = plt.imshow(data1, aspect='auto', cmap='cubehelix_r', origin='lower',\n",
    "                extent=[min(bin_centres), max(bin_centres), 0.5, 8.5])\n",
    "    plt.colorbar(im, label=\"Frequency\", pad=0.01)\n",
    "    for y in np.arange(1.5, 8, 1):\n",
    "        plt.hlines(y, xmin=min(bin_centres), xmax=max(bin_centres),colors='gray', linestyles='-', linewidth=0.9, alpha=0.7)\n",
    "    for x in np.arange(-4, 5, 1):\n",
    "        plt.vlines(x, ymin=0.5, ymax=8.5, colors='gray', linestyles='-', linewidth=0.9, alpha=0.7)\n",
    "    X, Y = np.meshgrid(bin_centres, np.arange(1,9))\n",
    "    contours = plt.contour(X, Y, data2, colors='black', linewidths=1.2)\n",
    "    plt.clabel(contours, inline=True, fontsize=8, fmt=\"%.3f\")\n",
    "    plt.xlabel(\"Wind ramp intensity (m/s)\")\n",
    "    plt.ylabel(\"Ramp duration (hours)\")\n",
    "    plt.title(f\"{months[m]} - Observations\")\n",
    "    plt.savefig(f\"/home/gopika/Bela/GISE/dpi_paper_plots/wind_ramps/heatmap_contours/finer_ramps_{months[m]}_obs.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3b38c-9c76-4696-b8bd-c32db22292a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "month_jumps_problist_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f5b20-db3c-4926-a5ea-7aef35485ff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year = 2017\n",
    "for m in range(len(months)):\n",
    "    month_jumps_countlist_era5 = []\n",
    "    month_jumps_problist_era5 = []\n",
    "    month_jumps_countlist_obs = []\n",
    "    month_jumps_problist_obs = []\n",
    "    for jump in jumps:\n",
    "        strow = sum(days_nonleap[:m])*24\n",
    "        endrow = sum(days_nonleap[:m+1])*24\n",
    "        \n",
    "        era5_data = df_era5[f'roc_ws_{year}_{jump}'][strow:endrow].dropna()\n",
    "        era5_counts, bin_edges = np.histogram(era5_data, bins=bins_era5_less[m]) # MORE\n",
    "        era5_probs = era5_counts / era5_counts.sum()\n",
    "        #bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        month_jumps_countlist_era5.append(era5_counts)\n",
    "        month_jumps_problist_era5.append(era5_probs)\n",
    "\n",
    "        obs_data = hourly_means_df_obs[f'roc_ws_jump_{jump}'][strow:endrow].dropna()\n",
    "        obs_counts, bin_edges = np.histogram(obs_data, bins=bins_obs_less[m]) # MORE\n",
    "        obs_probs = obs_counts / obs_counts.sum()\n",
    "        #bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        month_jumps_countlist_obs.append(obs_counts)\n",
    "        month_jumps_problist_obs.append(obs_probs)\n",
    "        \n",
    "    # ERA5 heatmap\n",
    "    data1 = np.array(month_jumps_countlist_era5)\n",
    "    data2 = np.array(month_jumps_problist_era5)\n",
    "    bin_centres = (bins_era5_less[m][:-1] + bins_era5_less[m][1:]) / 2 # MORE\n",
    "    # plot\n",
    "    plt.figure(figsize=(18,3))\n",
    "    im = plt.imshow(data1, aspect='auto', cmap='terrain_r', origin='lower',\n",
    "                extent=[min(bin_centres), max(bin_centres), 0.5, 8.5])\n",
    "    plt.colorbar(im, label=\"Frequency\", pad=0.01)\n",
    "    for y in np.arange(1.5, 8, 1):\n",
    "        plt.hlines(y, xmin=min(bin_centres), xmax=max(bin_centres), colors='gray', linestyles='-', linewidth=0.9, alpha=0.7)\n",
    "    for x in np.arange(-4, 5, 1):\n",
    "        plt.vlines(x, ymin=0.5, ymax=8.5, colors='gray', linestyles='-', linewidth=0.9, alpha=0.7)\n",
    "    X, Y = np.meshgrid(bin_centres, np.arange(1,9))\n",
    "    contours = plt.contour(X, Y, data2, colors='black', linewidths=1.2)\n",
    "    plt.clabel(contours, inline=True, fontsize=8, fmt=\"%.3f\")\n",
    "    plt.xlabel(\"Wind ramp intensity (m/s)\")\n",
    "    plt.ylabel(\"Ramp duration (hours)\")\n",
    "    plt.title(f\"{months[m]} - ERA5\")\n",
    "    plt.savefig(f\"/home/gopika/Bela/GISE/dpi_paper_plots/wind_ramps/heatmap_contours/coarser_ramps_{months[m]}_era5.png\", dpi=300)\n",
    "\n",
    "    # OBSV heatmap\n",
    "    data1 = np.array(month_jumps_countlist_obs)\n",
    "    data2 = np.array(month_jumps_problist_obs)\n",
    "    bin_centres = (bins_obs_less[m][:-1] + bins_obs_less[m][1:]) / 2 # MORE\n",
    "    # plot\n",
    "    plt.figure(figsize=(18,3))\n",
    "    im = plt.imshow(data1, aspect='auto', cmap='terrain_r', origin='lower',\n",
    "                extent=[min(bin_centres), max(bin_centres), 0.5, 8.5])\n",
    "    plt.colorbar(im, label=\"Frequency\", pad=0.01)\n",
    "    for y in np.arange(1.5, 8, 1):\n",
    "        plt.hlines(y, xmin=min(bin_centres), xmax=max(bin_centres),colors='gray', linestyles='-', linewidth=0.9, alpha=0.7)\n",
    "    for x in np.arange(-4, 5, 1):\n",
    "        plt.vlines(x, ymin=0.5, ymax=8.5, colors='gray', linestyles='-', linewidth=0.9, alpha=0.7)\n",
    "    X, Y = np.meshgrid(bin_centres, np.arange(1,9))\n",
    "    contours = plt.contour(X, Y, data2, colors='black', linewidths=1.2)\n",
    "    plt.clabel(contours, inline=True, fontsize=8, fmt=\"%.3f\")\n",
    "    plt.xlabel(\"Wind ramp intensity (m/s)\")\n",
    "    plt.ylabel(\"Ramp duration (hours)\")\n",
    "    plt.title(f\"{months[m]} - Observations\")\n",
    "    plt.savefig(f\"/home/gopika/Bela/GISE/dpi_paper_plots/wind_ramps/heatmap_contours/coarser_ramps_{months[m]}_obs.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041a233d-d9aa-46e0-bdb3-b27a9df929ab",
   "metadata": {},
   "source": [
    "### when are these ramps most probable to occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43afa47-e22f-4c3d-9576-80aba734716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_bins = np.arange(0, 25, 2)  # 24 bins for 24 hours\n",
    "bin_centres = (hour_bins[:-1] + hour_bins[1:]) / 2\n",
    "bin_centres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5355736-787f-460d-b8ec-bd7c599ad7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(len(months)):\n",
    "    era5_highramp_hrcounts = []\n",
    "    era5_highramp_hrprobs = []\n",
    "    obs_highramp_hrcounts = []\n",
    "    obs_highramp_hrprobs = []\n",
    "    for jump in jumps:\n",
    "        strow = sum(days_nonleap[:m])*24\n",
    "        endrow = sum(days_nonleap[:m+1])*24\n",
    "\n",
    "        era5_data = df_era5[f'roc_ws_{year}_{jump}'][strow:endrow].dropna()\n",
    "        era5_mean = era5_data.mean()\n",
    "        era5_std  = era5_data.std()\n",
    "        # Define standard deviation flanks\n",
    "        era5_lower = era5_mean - era5_std\n",
    "        era5_upper = era5_mean + era5_std\n",
    "        # Apply the dynamic thresholding based on ±1σ\n",
    "        era5_slice = df_era5.iloc[strow:endrow]\n",
    "        high_ramps = era5_slice['hours'][\n",
    "            (era5_slice[f'roc_ws_{year}_{jump}'] < era5_lower) |\n",
    "            (era5_slice[f'roc_ws_{year}_{jump}'] > era5_upper)\n",
    "        ].tolist()\n",
    "        hourlist = np.array(high_ramps)\n",
    "        era5_counts, bin_edges = np.histogram(hourlist, bins=hour_bins)\n",
    "        era5_probs = era5_counts / era5_counts.sum()\n",
    "        era5_highramp_hrcounts.append(era5_counts)\n",
    "        era5_highramp_hrprobs.append(era5_probs)\n",
    "\n",
    "        obs_data = hourly_means_df_obs[f'roc_ws_jump_{jump}'][strow:endrow].dropna()\n",
    "        obs_mean = obs_data.mean()\n",
    "        obs_std  = obs_data.std()\n",
    "        # Define standard deviation flanks\n",
    "        obs_lower = obs_mean - obs_std\n",
    "        obs_upper = obs_mean + obs_std\n",
    "        # Apply the dynamic thresholding based on ±1σ\n",
    "        obs_slice = hourly_means_df_obs.iloc[strow:endrow]\n",
    "        high_ramps = obs_slice['roundedhr'][\n",
    "            (obs_slice[f'roc_ws_jump_{jump}'] < obs_lower) |\n",
    "            (obs_slice[f'roc_ws_jump_{jump}'] > obs_upper)\n",
    "        ].tolist()\n",
    "        hourlist = np.array(high_ramps)\n",
    "        obs_counts, bin_edges = np.histogram(hourlist, bins=hour_bins)\n",
    "        obs_probs = obs_counts / obs_counts.sum()\n",
    "        obs_highramp_hrcounts.append(obs_counts)\n",
    "        obs_highramp_hrprobs.append(obs_probs)\n",
    "    \n",
    "    # ERA5 heatmap\n",
    "    data1 = np.array(era5_highramp_hrcounts)\n",
    "    data2 = np.array(era5_highramp_hrprobs)\n",
    "    # plot\n",
    "    plt.figure(figsize=(6,3))\n",
    "    im = plt.imshow(data1, aspect='auto', cmap='terrain_r', origin='lower',\n",
    "                extent=[min(bin_centres), max(bin_centres), 0.5, 8.5])\n",
    "    plt.colorbar(im, label=\"Frequency\", pad=0.03)\n",
    "    for y in np.arange(1.5, 8, 1):\n",
    "        plt.hlines(y, xmin=min(bin_centres), xmax=max(bin_centres), colors='gray', linestyles='-', linewidth=0.9, alpha=0.7)\n",
    "    #for x in bin_centres:\n",
    "        plt.vlines(x, ymin=0.5, ymax=8.5, colors='gray', linestyles='-', linewidth=0.9, alpha=0.7)\n",
    "    X, Y = np.meshgrid(bin_centres, np.arange(1,9))\n",
    "    contours = plt.contour(X, Y, data2, colors='black', linewidths=1.2)\n",
    "    plt.clabel(contours, inline=True, fontsize=8, fmt=\"%.3f\")\n",
    "    plt.xlabel(\"Hour of day\")\n",
    "    plt.ylabel(\"Ramp duration (hours)\")\n",
    "    plt.title(f\"{months[m]} - ERA5\")\n",
    "    plt.savefig(f\"/home/gopika/Bela/GISE/dpi_paper_plots/wind_ramps/heatmap_contours/hours_{months[m]}_era5.png\", dpi=300)\n",
    "\n",
    "    # OBSV heatmap\n",
    "    data1 = np.array(obs_highramp_hrcounts)\n",
    "    data2 = np.array(obs_highramp_hrprobs)\n",
    "    # plot\n",
    "    plt.figure(figsize=(6,3))\n",
    "    im = plt.imshow(data1, aspect='auto', cmap='terrain_r', origin='lower',\n",
    "                extent=[min(bin_centres), max(bin_centres), 0.5, 8.5])\n",
    "    plt.colorbar(im, label=\"Frequency\", pad=0.03)\n",
    "    for y in np.arange(1.5, 8, 1):\n",
    "        plt.hlines(y, xmin=min(bin_centres), xmax=max(bin_centres),colors='gray', linestyles='-', linewidth=0.9, alpha=0.7)\n",
    "    #for x in bin_centres:\n",
    "        plt.vlines(x, ymin=0.5, ymax=8.5, colors='gray', linestyles='-', linewidth=0.9, alpha=0.7)\n",
    "    X, Y = np.meshgrid(bin_centres, np.arange(1,9))\n",
    "    contours = plt.contour(X, Y, data2, colors='black', linewidths=1.2)\n",
    "    plt.clabel(contours, inline=True, fontsize=8, fmt=\"%.3f\")\n",
    "    plt.xlabel(\"Hour of day\")\n",
    "    plt.ylabel(\"Ramp duration (hours)\")\n",
    "    plt.title(f\"{months[m]} - Observations\")\n",
    "    plt.savefig(f\"/home/gopika/Bela/GISE/dpi_paper_plots/wind_ramps/heatmap_contours/hours_{months[m]}_obs.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874cac1-f553-40eb-9f3b-5313f9c1b220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
